{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c203f99-0501-4425-a0c5-042a4d52fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculates MFIS estimates for failure probability using ECL\n",
    "adaptive designs from the Hartmann6 experiment and space-filling designs.\n",
    "\n",
    "@author: D. Austin Cole  austin.cole8@vt.edu\n",
    "\"\"\"\n",
    "\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyDOE import lhs\n",
    "import scipy.stats as ss\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor as GPR\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "import os\n",
    "import sys\n",
    "fileDir = os.getcwd()\n",
    "sourcePath = os.path.join(fileDir, 'MFISPy')\n",
    "sys.path.append(sourcePath)\n",
    "from mfis import BiasingDistribution\n",
    "from mfis import MultiFidelityIS\n",
    "from mfis.mv_independent_distribution import MVIndependentDistribution\n",
    "\n",
    "sourcePath = fileDir\n",
    "sys.path.append(sourcePath)\n",
    "from eclGP import *\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import dill\n",
    "from psis import psislw\n",
    "import glob\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "563d2113-736f-49a4-86fa-2b23f3c70864",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"data/Ex_3\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ba2603-ecc4-48f0-b6ba-11d8a1239e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Start_time = time.time()\n",
    "today = date.today()\n",
    "case = 'Ex3'\n",
    "Model = Numerical_Ex3()\n",
    "bounds = ((-5,5),(-5,5),(-5,5),(-5,5),(-5,5),(-5,5),(-5,5),(-5,5),(-5,5),(-5,5))\n",
    "threshold = 18.74\n",
    "dim = len(bounds)\n",
    "alpha = 0.01\n",
    "\n",
    "N_HIGH_FIDELITY_INPUTS = 1200\n",
    "n_init = 10*dim\n",
    "n_select = 600 - n_init\n",
    "MC_REPS = 25\n",
    "batch_size = 10\n",
    "\n",
    "mfis_probs = np.ones((MC_REPS, 3))\n",
    "#gauss_kernel = 1.0 * RBF(length_scale= np.repeat(0.5, dim),length_scale_bounds=(1e-4, 1e4))\n",
    "# Stochastic\n",
    "gauss_kernel = 1.0 * RBF(length_scale= np.repeat(0.5, dim),length_scale_bounds=(1e-4, 1e4)) + WhiteKernel(noise_level=1e-2, noise_level_bounds=(1e-10, 1e1))\n",
    "\n",
    "\n",
    "\n",
    "###############################\n",
    "# 0. Build Initial design\n",
    "###############################\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "stat_results = np.zeros((MC_REPS,dim+1))\n",
    "initial_designs = np.zeros((n_init, (dim+1)*MC_REPS))\n",
    "today = date.today()\n",
    "file_date = today.strftime(\"%m%d%y\")\n",
    "\n",
    "os.makedirs(\"data/Ex_3\", exist_ok=True)\n",
    "\n",
    "for i in range(MC_REPS):\n",
    "    X0 = lhs(dim, n_init)\n",
    "    X0 = ss.norm.ppf(X0)\n",
    "    Y0 = Model.predict(X0)\n",
    "\n",
    "    initial_designs[:,((dim+1)*i):((dim+1)*(i+1))] = \\\n",
    "        np.hstack((X0, Y0.reshape((-1,1))))\n",
    "\n",
    "\n",
    "np.savetxt(f'data/Ex_3/Initial_designs_{case}_{file_date}.csv',initial_designs, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef0e16bb-6d27-4fa6-afdc-ab249c12065a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/pkgs/arc/python3.11-anaconda/2024.02-1/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 2 of parameter k1__k2__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/sw/pkgs/arc/python3.11-anaconda/2024.02-1/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 4 of parameter k1__k2__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/sw/pkgs/arc/python3.11-anaconda/2024.02-1/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 7 of parameter k1__k2__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "100%|██████████| 500/500 [29:54<00:00,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# 1. Build ECL GP\n",
    "###############################\n",
    "initial_designs_df = pd.read_csv(f\"data/Ex_3/Initial_designs_{case}_{file_date}.csv\",header=None)\n",
    "initial_designs = np.array(initial_designs_df)\n",
    "ecl_designs = np.zeros((n_init+n_select, (dim+1)*MC_REPS))\n",
    "ecl_times = np.zeros((MC_REPS,))\n",
    "ecl_batch_designs = np.zeros((n_init+n_select, (dim+1)*MC_REPS))\n",
    "ecl_batch_times = np.zeros((MC_REPS,))\n",
    "\n",
    "def limit_state_function(y):\n",
    "    return y - threshold\n",
    "\n",
    "for i in range(MC_REPS): \n",
    "    X0 = initial_designs[:,((dim+1)*i):((dim+1)*(i+1)-1)]\n",
    "    Y0 = initial_designs[:,(dim+1)*(i+1)-1]\n",
    "      \n",
    "    ## Adaptive design with ECL\n",
    "    ecl_start_time = time.time()\n",
    "    init_gp = GPR(kernel=gauss_kernel, alpha=1e-6)\n",
    "    init_gp.fit(X0, Y0)\n",
    "    eclgp = EntropyContourLocatorGP(init_gp, limit_state_function)\n",
    "    eclgp.fit(n_select, Model, bounds)\n",
    "\n",
    "    ecl_designs[:,((dim+1)*i):((dim+1)*(i+1))] = \\\n",
    "        np.hstack((eclgp.X_, eclgp.y_.reshape((-1,1))))\n",
    "    ecl_times[i] = (time.time() - ecl_start_time)/60\n",
    "    \n",
    "#     ## Adaptive design with ECL.batch\n",
    "#     ecl_batch_start_time = time.time()\n",
    "#     eclgp_batch = EntropyContourLocatorGP(init_gp,limit_state_function)\n",
    "    \n",
    "#     eclgp_batch.fit(np.int(n_select/batch_size), Model, bounds, batch_size=batch_size)    \n",
    "#     ecl_batch_designs[:,((dim+1)*i):((dim+1)*(i+1))] = \\\n",
    "#         np.hstack((eclgp_batch.X_, eclgp_batch.y_.reshape((-1,1))))\n",
    "#     ecl_batch_times[i] = (time.time() - ecl_batch_start_time)/60\n",
    "\n",
    "    print(i)\n",
    "    np.savetxt(f'data/Ex_3/ecl_designs_{case}_{file_date}.csv', \n",
    "                ecl_designs, delimiter = \",\")\n",
    "    np.savetxt(f'data/Ex_3/ecl_designs_times_{case}_{file_date}.csv', \n",
    "            ecl_times, delimiter = \",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b66582d0-2d77-498a-9069-7ba5bb06500c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/pkgs/arc/python3.11-anaconda/2024.02-1/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 3 of parameter k1__k2__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/sw/pkgs/arc/python3.11-anaconda/2024.02-1/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 5 of parameter k1__k2__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0 th Experiment Total Elapsed time:  8.563257932662964\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "# 2. MFIS\n",
    "####################################\n",
    "unif_dist = ss.uniform(0,1)\n",
    "m1 = 0\n",
    "s1 = 1\n",
    "norm_dist = ss.norm(loc=m1, scale=s1)\n",
    "\n",
    "input_distribution = MVIndependentDistribution(\n",
    "    distributions=[norm_dist, norm_dist, norm_dist, norm_dist, norm_dist, norm_dist, norm_dist, norm_dist, norm_dist, norm_dist])\n",
    "\n",
    "## Estimate failure probability (alpha)\n",
    "'''\n",
    "num_failures = np.zeros((100,))\n",
    "for i in range(len(num_failures)):\n",
    "    new_X = input_distribution.draw_samples(1000000)\n",
    "    new_Y = hartmann_model.predict(new_X)\n",
    "    num_failures[i] = np.sum(hartmann_limit_state_function(new_Y)>0)\n",
    "    print(num_failures[i])\n",
    "    print(i)\n",
    "alpha = np.mean(num_failures)/len(new_X)\n",
    "'''\n",
    "mfis_probs = np.ones((MC_REPS, 1))\n",
    "\n",
    "ecl_designs_df = pd.read_csv(f\"data/Ex_3/ecl_designs_{case}_{file_date}.csv\",header=None) #pd.read_csv(f\"data/ecl_designs_{case}_{file_date}.csv\",header=None)\n",
    "ecl_designs = np.array(ecl_designs_df)\n",
    "\n",
    "\n",
    "weight_is_all_sample_list = []\n",
    "weight_ucb_all_sample_list = []\n",
    "    \n",
    "for j in range(MC_REPS): \n",
    "    start_time = time.time()\n",
    "    ecl_gp = None\n",
    "       \n",
    "    ## ECL\n",
    "    design_X = ecl_designs[:, ((dim+1)*j):((dim+1)*(j+1)-1)]\n",
    "    design_Y = ecl_designs[:, (dim+1)*(j+1)-1]\n",
    "    ecl_gp =  GPR(kernel=gauss_kernel, alpha=1e-6)\n",
    "    ecl_gp.fit(design_X, design_Y)\n",
    "    \n",
    "    ## ECL-Batch\n",
    "#     design_X_batch = ecl_designs_batch[:, ((dim+1)*j):((dim+1)*(j+1)-1)]\n",
    "#     design_Y_batch = ecl_designs_batch[:, (dim+1)*(j+1)-1]\n",
    "#     ecl_gp_batch =  GPR(kernel=gauss_kernel, alpha=1e-6)\n",
    "#     ecl_gp_batch.fit(design_X_batch, design_Y_batch)\n",
    "            \n",
    "  \n",
    "    # Initialize Biasing Distributions\n",
    "    ecl_bd =  BiasingDistribution(trained_surrogate=ecl_gp,\n",
    "                            limit_state=limit_state_function,\n",
    "                            input_distribution=input_distribution)\n",
    "    ecl_bd_ucb =  BiasingDistribution(trained_surrogate=ecl_gp,\n",
    "                            limit_state=limit_state_function,\n",
    "                            input_distribution=input_distribution)\n",
    "    \n",
    "    ## Fit Biasing Distributions\n",
    "    ecl_failed_inputs = np.empty((0, dim))   \n",
    "    ecl_failed_inputs_ucb = np.empty((0, dim))\n",
    "\n",
    "    # Get sample outputs from GPs and classify failures  \n",
    "    for k in range(100):\n",
    "        sample_inputs = input_distribution.draw_samples(10000) \n",
    "        \n",
    "        ecl_sample_outputs, ecl_sample_std = \\\n",
    "            ecl_gp.predict(sample_inputs, return_std=True)\n",
    "        ecl_failed_inputs_new = sample_inputs[\n",
    "            limit_state_function(ecl_sample_outputs.flatten()) > 0,:]\n",
    "        ecl_failed_inputs = np.vstack((ecl_failed_inputs,\n",
    "                                       ecl_failed_inputs_new))\n",
    "\n",
    "        ecl_failed_inputs_ucb_new = sample_inputs[\n",
    "            limit_state_function(\n",
    "                ecl_sample_outputs.flatten() + 1.645*ecl_sample_std) > 0,:]\n",
    "        ecl_failed_inputs_ucb = np.vstack((ecl_failed_inputs_ucb,\n",
    "                                           ecl_failed_inputs_ucb_new))\n",
    "        \n",
    "        if (k % 100) == 0:\n",
    "            print(k)\n",
    "\n",
    "        \n",
    "\n",
    "    print(j)\n",
    "    # End timer\n",
    "    end_time = time.time()\n",
    "    # Calculate elapsed time\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(j,'th Experiment',\"Total Elapsed time: \", elapsed_time) \n",
    "    \n",
    "    mfis_probs_df = pd.DataFrame(mfis_probs)\n",
    "    mfis_probs_df = mfis_probs_df.rename(columns={0:'ECL'})\n",
    "    mfis_probs_df.to_csv(f'data/Ex_3/{case}_mfis_estimates_Experiment_{file_date}_{MC_REPS}.csv',index=False)\n",
    "dill.dump_session(f'{case}_Stochastic_num_{N_HIGH_FIDELITY_INPUTS}_{MC_REPS}rep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569cb853-0cfc-4faa-8668-160846696709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
